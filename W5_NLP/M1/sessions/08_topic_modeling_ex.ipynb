{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18298de9",
   "metadata": {},
   "source": [
    "# Topic Modeling: Organizing Unlabeled CVs with LDA\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **Topic Modeling** using **Latent Dirichlet Allocation (LDA)** to organize unlabeled CVs (resumes) by automatically discovering hidden topics. Unlike supervised classification, topic modeling works with completely unlabeled data, making it ideal for organizing large document collections without manual labeling. You'll learn how to apply LDA to discover topics, interpret results, and organize documents based on their dominant topics.\n",
    "\n",
    "> \"The best way to find a needle in a haystack is to organize the haystack first.\"\n",
    "\n",
    "**The Problem**: You have a folder full of CVs—unlabeled, unorganized. You need to find candidates for specific roles, but manually reading through hundreds of CVs is impossible.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Understand what Topic Modeling is and why it's useful for unsupervised document organization\n",
    "- Learn how LDA (Latent Dirichlet Allocation) discovers hidden topics in text collections\n",
    "- Apply LDA to organize unlabeled documents automatically\n",
    "- Interpret topic modeling results by examining top words and document-topic distributions\n",
    "- Organize documents into folders based on their dominant topics\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Introduction to Topic Modeling** - What it is and why it's useful\n",
    "2. **What is LDA?** - Understanding Latent Dirichlet Allocation\n",
    "3. **The Pipeline** - Complete workflow from data loading to organization\n",
    "4. **Step 1: Loading Data** - Reading CVs from JSON files\n",
    "5. **Step 2: Preprocessing** - Cleaning and preparing text\n",
    "6. **Step 3: Vectorization** - Converting text to document-term matrix\n",
    "7. **Step 4: Training LDA** - Discovering topics automatically\n",
    "8. **Step 5: Analyzing Results** - Interpreting discovered topics\n",
    "9. **Step 6: Organizing Documents** - Creating folders and organizing CVs by topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded0fed",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "**Topic Modeling** is an **unsupervised learning** task that discovers hidden topics in a collection of unlabeled documents. Unlike classification (which requires labeled data), topic modeling finds patterns automatically.\n",
    "\n",
    "**Example applications:**\n",
    "- **Organizing unlabeled documents**: Group CVs by field (AI/ML, Data Analysis, etc.) without manual labeling\n",
    "- **Understanding large text collections**: Discover what themes exist in news archives, research papers, or social media\n",
    "- **Content recommendation**: Find documents similar to a given document based on topic similarity\n",
    "\n",
    "**Why it's useful:**\n",
    "- No labels needed: works with completely unlabeled data\n",
    "- Interpretable: topics are defined by their top words, making them understandable\n",
    "- Scalable: can process large document collections\n",
    "- Flexible: number of topics can be adjusted based on the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f61c3f",
   "metadata": {},
   "source": [
    "## What is LDA?\n",
    "\n",
    "**Latent Dirichlet Allocation (LDA)** is a probabilistic model that discovers hidden topics in a collection of documents.\n",
    "\n",
    "**Key idea**: \n",
    "- Each document is a **mixture of topics** (e.g., 70% AI/ML, 20% Data Analysis, 10% Software Engineering)\n",
    "- Each topic is a **distribution over words** (e.g., Topic 1: 30% \"PyTorch\", 25% \"TensorFlow\", 20% \"NLP\"...)\n",
    "- LDA discovers these topics automatically by finding words that co-occur together\n",
    "\n",
    "**For our CVs**: LDA will discover topics like \"AI/ML\", \"Data Analysis\", \"Big Data\" by looking at which words appear together, then assign each CV to the most relevant topic(s).\n",
    "\n",
    "**Reference**: Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). [Latent dirichlet allocation](https://dl.acm.org/doi/10.5555/944919.944937). *Journal of machine Learning research*, 3(Jan), 993-1022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbf82c0",
   "metadata": {},
   "source": [
    "![Left: BoW. Right: LDA](../assets/lda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7018f6c",
   "metadata": {},
   "source": [
    "## The Pipeline\n",
    "\n",
    "1. **Load CVs**: Read all JSON files from topic folders using glob patterns and extract structured fields\n",
    "2. **Preprocess**: Clean the text (remove URLs, emails, etc.)\n",
    "3. **Vectorize**: Convert text to document-term matrix (Bag of Words)\n",
    "4. **Train LDA**: Discover topics automatically\n",
    "5. **Analyze Results**: See what topics were found and which CVs belong to each\n",
    "6. **Organize**: Create folders and copy CVs based on their dominant topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff53c5d",
   "metadata": {},
   "source": [
    "## Step 1: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9332f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File > Open Folder > W5_NLP\n",
    "# (VS Code root should be at W5_NLP)\n",
    "# Then run: `uv sync`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5dc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1aa196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CVs from JSON files in all topic folders\n",
    "cv_dir = Path('../datasets/CVs')\n",
    "# Use glob pattern to find all JSON files in Topic_* subdirectories, excluding English versions\n",
    "cv_files = sorted([f for f in cv_dir.glob('Topic_*/*.json') if not f.name.endswith('_en.json')])\n",
    "\n",
    "# Load and extract structured data from JSON\n",
    "cvs_data = []\n",
    "cv_names = []\n",
    "cv_file_paths = []  # Store original file paths for later copying\n",
    "\n",
    "for file in cv_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        cvs_data.append(data)\n",
    "        cv_names.append(file.stem)\n",
    "        cv_file_paths.append(file)  # Store the full path\n",
    "\n",
    "print(f\"Loaded {len(cvs_data)} CV files from {len(set(f.parent.name for f in cv_files))} topic folders:\")\n",
    "for i, name in enumerate(cv_names, 1):\n",
    "    print(f\"  {i}. {name}\")\n",
    "\n",
    "# Combine structured fields into text for each CV\n",
    "def combine_cv_fields(cv_json):\n",
    "    \"\"\"Combine Heading, Skills, Projects, Experience, Education into a single text\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Add heading\n",
    "    if 'Heading' in cv_json:\n",
    "        parts.append(cv_json['Heading'])\n",
    "    \n",
    "    # Add skills (join list items)\n",
    "    if 'Skills' in cv_json:\n",
    "        skills_text = ' '.join(cv_json['Skills']) if isinstance(cv_json['Skills'], list) else cv_json['Skills']\n",
    "        parts.append(skills_text)\n",
    "    \n",
    "    # Add projects\n",
    "    if 'Projects' in cv_json:\n",
    "        projects_text = ' '.join(cv_json['Projects']) if isinstance(cv_json['Projects'], list) else cv_json['Projects']\n",
    "        parts.append(projects_text)\n",
    "    \n",
    "    # Add experience\n",
    "    if 'Experience' in cv_json:\n",
    "        exp_text = ' '.join(cv_json['Experience']) if isinstance(cv_json['Experience'], list) else cv_json['Experience']\n",
    "        parts.append(exp_text)\n",
    "    \n",
    "    # Add education\n",
    "    if 'Education' in cv_json:\n",
    "        edu_text = ' '.join(cv_json['Education']) if isinstance(cv_json['Education'], list) else cv_json['Education']\n",
    "        parts.append(edu_text)\n",
    "    \n",
    "    return ' '.join(parts)\n",
    "\n",
    "# Convert JSON data to text\n",
    "cvs = [combine_cv_fields(cv_data) for cv_data in cvs_data]\n",
    "print(f\"\\nCombined structured data into text for {len(cvs)} CVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbef1b5",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean text: remove URLs, emails, and normalize whitespace\"\"\"\n",
    "    # Remove emails and URLs\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Keep only Arabic/English letters and numbers\n",
    "    text = re.sub(r'[^\\w\\s\\u0600-\\u06FF]', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Preprocess all CVs\n",
    "cvs_processed = [preprocess_text(cv) for cv in cvs]\n",
    "print(f\"Preprocessed {len(cvs_processed)} CVs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e1f26b",
   "metadata": {},
   "source": [
    "## Step 3: Prepare Data for LDA\n",
    "\n",
    "Convert text to a document-term matrix (same as Bag of Words from classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63cfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,  # Top 1000 words\n",
    "    min_df=2,           # Word must appear in at least 2 CVs\n",
    "    max_df=0.8          # Ignore words in >80% of CVs\n",
    ")\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(cvs_processed)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Document-Term Matrix: {doc_term_matrix.shape[0]} CVs × {doc_term_matrix.shape[1]} words\")\n",
    "print(f\"Sparsity: {(1 - doc_term_matrix.nnz / (doc_term_matrix.shape[0] * doc_term_matrix.shape[1])) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29757a7c",
   "metadata": {},
   "source": [
    "## Step 4: Train LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "n_topics = 3  # Number of topics to discover\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=10,\n",
    "    learning_method='online'\n",
    ")\n",
    "\n",
    "print(f\"Training LDA to discover {n_topics} topics...\")\n",
    "lda.fit(doc_term_matrix)\n",
    "print(\"✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b719dc1",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Results\n",
    "\n",
    "Let's see what topics LDA discovered and which words define each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b72bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top words for each topic\n",
    "def display_topics(model, feature_names, n_top_words=10):\n",
    "    \"\"\"Display top words for each topic\"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        top_weights = [topic[i] for i in top_words_idx]\n",
    "        \n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\"  Top words:\", \", \".join(top_words))\n",
    "        print(\"  Weights:\", [f\"{w:.3f}\" for w in top_weights])\n",
    "\n",
    "display_topics(lda, feature_names, n_top_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66088b1",
   "metadata": {},
   "source": [
    "**Interpreting the topics**: Look at the top words for each topic. Can you guess what each topic represents? For example:\n",
    "- Topic with \"PyTorch\", \"TensorFlow\", \"NLP\" → probably AI/ML\n",
    "- Topic with \"Tableau\", \"Power BI\", \"dashboard\" → probably Data Analysis\n",
    "- Topic with \"Hadoop\", \"Spark\", \"Kafka\" → probably Big Data\n",
    "\n",
    "Now let's see which CV belongs to which topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f168fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each CV\n",
    "doc_topic_dist = lda.transform(doc_term_matrix)\n",
    "\n",
    "# Find dominant topic for each CV\n",
    "dominant_topics = doc_topic_dist.argmax(axis=1)\n",
    "\n",
    "# Create a DataFrame to see results\n",
    "df_results = pd.DataFrame({\n",
    "    'CV': cv_names,\n",
    "    'Dominant Topic': dominant_topics + 1,\n",
    "    'Topic Probabilities': [dist for dist in doc_topic_dist]\n",
    "})\n",
    "\n",
    "# Show which CVs belong to which topic\n",
    "print(\"CV Assignment to Topics:\")\n",
    "print(\"=\" * 60)\n",
    "for topic_id in range(n_topics):\n",
    "    topic_cvs = df_results[df_results['Dominant Topic'] == topic_id + 1]\n",
    "    print(f\"\\nTopic {topic_id + 1} ({len(topic_cvs)} CVs):\")\n",
    "    for idx, row in topic_cvs.iterrows():\n",
    "        prob = row['Topic Probabilities'][topic_id]\n",
    "        print(f\"  - {row['CV']} ({prob:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086c24a",
   "metadata": {},
   "source": [
    "## Step 6: Organize CVs into Folders\n",
    "\n",
    "Now comes the practical part: **automatically organize CVs into folders** based on their dominant topic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory structure\n",
    "output_dir = Path('output/organized_cvs')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create a folder for each topic\n",
    "for topic_id in range(n_topics):\n",
    "    topic_dir = output_dir / f\"Topic_{topic_id + 1}\"\n",
    "    topic_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy each CV to its topic folder\n",
    "for idx, (cv_name, topic_id, source_file) in enumerate(zip(cv_names, dominant_topics, cv_file_paths)):\n",
    "    target_dir = output_dir / f\"Topic_{topic_id + 1}\"\n",
    "    target_file = target_dir / f\"{cv_name}.json\"\n",
    "    \n",
    "    shutil.copy2(source_file, target_file)\n",
    "    print(f\"Copied {cv_name}.json → Topic_{topic_id + 1}/\")\n",
    "\n",
    "print(f\"\\n✓ Organization complete! CVs are now in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5be03",
   "metadata": {},
   "source": [
    "### Verify the Organization\n",
    "\n",
    "Let's check what's in each folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show contents of each topic folder\n",
    "for topic_id in range(n_topics):\n",
    "    topic_dir = output_dir / f\"Topic_{topic_id + 1}\"\n",
    "    files = list(topic_dir.glob('*.json'))\n",
    "    print(f\"\\nTopic_{topic_id + 1}/ ({len(files)} CVs):\")\n",
    "    for f in sorted(files):\n",
    "        print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b48759d",
   "metadata": {},
   "source": [
    "## **Student Exercise**: discover topics on a dataset of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffffa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "\n",
    "categories = ['sci.space', 'sci.med', 'comp.graphics', 'rec.sport.baseball']\n",
    "\n",
    "dataset = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46913c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "clean_docs = [preprocess_text(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72940dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (2368, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "noise_words = [\n",
    "    'just', 'don', 'like', 'think', 'know', 'people', 'time', 'good', \n",
    "    've', 'way', 'does', 'really', 'make', 'years', 'did', 'sure', \n",
    "    'work', 'say', 'things', 'point'\n",
    "]\n",
    "my_stop_words = list(ENGLISH_STOP_WORDS) + noise_words\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=1000,\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    stop_words=my_stop_words \n",
    ")\n",
    "\n",
    "doc_term_matrix = vectorizer.fit_transform(clean_docs)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"Matrix shape: {doc_term_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "616460dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, n_components=4,\n",
       "                          random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LatentDirichletAllocation</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\">?<span>Documentation for LatentDirichletAllocation</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=n_components,-int%2C%20default%3D10\">\n",
       "            n_components\n",
       "            <span class=\"param-doc-description\">n_components: int, default=10<br><br>Number of topics.<br><br>.. versionchanged:: 0.19<br>    ``n_topics`` was renamed to ``n_components``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('doc_topic_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=doc_topic_prior,-float%2C%20default%3DNone\">\n",
       "            doc_topic_prior\n",
       "            <span class=\"param-doc-description\">doc_topic_prior: float, default=None<br><br>Prior of document topic distribution `theta`. If the value is None,<br>defaults to `1 / n_components`.<br>In [1]_, this is called `alpha`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('topic_word_prior',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=topic_word_prior,-float%2C%20default%3DNone\">\n",
       "            topic_word_prior\n",
       "            <span class=\"param-doc-description\">topic_word_prior: float, default=None<br><br>Prior of topic word distribution `beta`. If the value is None, defaults<br>to `1 / n_components`.<br>In [1]_, this is called `eta`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_method,-%7B%27batch%27%2C%20%27online%27%7D%2C%20default%3D%27batch%27\">\n",
       "            learning_method\n",
       "            <span class=\"param-doc-description\">learning_method: {'batch', 'online'}, default='batch'<br><br>Method used to update `_component`. Only used in :meth:`fit` method.<br>In general, if the data size is large, the online update will be much<br>faster than the batch update.<br><br>Valid options:<br><br>- 'batch': Batch variational Bayes method. Use all training data in each EM<br>  update. Old `components_` will be overwritten in each iteration.<br>- 'online': Online variational Bayes method. In each EM update, use mini-batch<br>  of training data to update the ``components_`` variable incrementally. The<br>  learning rate is controlled by the ``learning_decay`` and the<br>  ``learning_offset`` parameters.<br><br>.. versionchanged:: 0.20<br>    The default learning method is now ``\"batch\"``.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;online&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_decay',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_decay,-float%2C%20default%3D0.7\">\n",
       "            learning_decay\n",
       "            <span class=\"param-doc-description\">learning_decay: float, default=0.7<br><br>It is a parameter that control learning rate in the online learning<br>method. The value should be set between (0.5, 1.0] to guarantee<br>asymptotic convergence. When the value is 0.0 and batch_size is<br>``n_samples``, the update method is same as batch learning. In the<br>literature, this is called kappa.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_offset',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=learning_offset,-float%2C%20default%3D10.0\">\n",
       "            learning_offset\n",
       "            <span class=\"param-doc-description\">learning_offset: float, default=10.0<br><br>A (positive) parameter that downweights early iterations in online<br>learning.  It should be greater than 1.0. In the literature, this is<br>called tau_0.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=max_iter,-int%2C%20default%3D10\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=10<br><br>The maximum number of passes over the training data (aka epochs).<br>It only impacts the behavior in the :meth:`fit` method, and not the<br>:meth:`partial_fit` method.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('batch_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=batch_size,-int%2C%20default%3D128\">\n",
       "            batch_size\n",
       "            <span class=\"param-doc-description\">batch_size: int, default=128<br><br>Number of documents to use in each EM iteration. Only used in online<br>learning.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">128</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('evaluate_every',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=evaluate_every,-int%2C%20default%3D-1\">\n",
       "            evaluate_every\n",
       "            <span class=\"param-doc-description\">evaluate_every: int, default=-1<br><br>How often to evaluate perplexity. Only used in `fit` method.<br>set it to 0 or negative number to not evaluate perplexity in<br>training at all. Evaluating perplexity can help you check convergence<br>in training process, but it will also increase total training time.<br>Evaluating perplexity in every iteration might increase training time<br>up to two-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('total_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=total_samples,-int%2C%20default%3D1e6\">\n",
       "            total_samples\n",
       "            <span class=\"param-doc-description\">total_samples: int, default=1e6<br><br>Total number of documents. Only used in the :meth:`partial_fit` method.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000000.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('perp_tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=perp_tol,-float%2C%20default%3D1e-1\">\n",
       "            perp_tol\n",
       "            <span class=\"param-doc-description\">perp_tol: float, default=1e-1<br><br>Perplexity tolerance. Only used when ``evaluate_every`` is greater than 0.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('mean_change_tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=mean_change_tol,-float%2C%20default%3D1e-3\">\n",
       "            mean_change_tol\n",
       "            <span class=\"param-doc-description\">mean_change_tol: float, default=1e-3<br><br>Stopping tolerance for updating document topic distribution in E-step.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_doc_update_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=max_doc_update_iter,-int%2C%20default%3D100\">\n",
       "            max_doc_update_iter\n",
       "            <span class=\"param-doc-description\">max_doc_update_iter: int, default=100<br><br>Max number of iterations for updating document topic distribution in<br>the E-step.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to use in the E-step.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Verbosity level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Pass an int for reproducible results across multiple function calls.<br>See :term:`Glossary <random_state>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_components=4,\n",
       "                          random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=4,\n",
    "    random_state=42,\n",
    "    learning_method='online',\n",
    "    max_iter=10\n",
    ")\n",
    "\n",
    "lda.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328dec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: Sports\n",
      "Topic 2: Space\n",
      "Topic 3: Graphics\n",
      "Topic 4: Medicine\n"
     ]
    }
   ],
   "source": [
    "topic_keywords = {\n",
    "    \"Space\": [\"space\", \"nasa\", \"orbit\", \"moon\", \"launch\", \"earth\"],\n",
    "    \"Sports\": [\"game\", \"team\", \"play\", \"baseball\", \"score\", \"win\"],\n",
    "    \"Medicine\": [\"doctor\", \"health\", \"disease\", \"med\", \"pain\", \"medical\"],\n",
    "    \"Graphics\": [\"image\", \"file\", \"jpeg\", \"graphics\", \"video\", \"format\"]\n",
    "}\n",
    "\n",
    "def get_topic_label(top_words):\n",
    "    best_label = \"Unknown\"\n",
    "    max_match = 0\n",
    "    \n",
    "    for label, keywords in topic_keywords.items():\n",
    "        matches = sum(1 for word in top_words if word in keywords)\n",
    "        if matches > max_match:\n",
    "            max_match = matches\n",
    "            best_label = label\n",
    "    return best_label\n",
    "\n",
    "topic_names = {}\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_indices = topic.argsort()[:-15:-1]\n",
    "    top_words = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    label = get_topic_label(top_words)\n",
    "    topic_names[topic_idx] = label\n",
    "    print(f\"Topic {topic_idx + 1}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cb4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "output_dir = 'output/organized_newsgroups'\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "doc_topic_dist = lda.transform(doc_term_matrix)\n",
    "dominant_topics = doc_topic_dist.argmax(axis=1)\n",
    "\n",
    "for idx, (text, topic_id) in enumerate(zip(documents, dominant_topics)):\n",
    "    folder_name = topic_names[topic_id]\n",
    "    \n",
    "    folder_path = os.path.join(output_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    with open(os.path.join(folder_path, f\"doc_{idx}.txt\"), 'w', encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b213d4f9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**What we accomplished**:\n",
    "1. ✅ Loaded unlabeled CVs from a folder\n",
    "2. ✅ Preprocessed the text data\n",
    "3. ✅ Created a document-term matrix\n",
    "4. ✅ Trained an LDA model to discover topics\n",
    "5. ✅ Analyzed which CVs belong to which topic\n",
    "6. ✅ **Automatically organized CVs into folders** based on discovered topics\n",
    "\n",
    "**Key Takeaways**:\n",
    "- **LDA discovers topics automatically** by finding words that co-occur together\n",
    "- **Each document is a mixture of topics** - LDA assigns probabilities\n",
    "- **Topic modeling is unsupervised** - no labels needed!\n",
    "- **Practical application**: Organize unlabeled documents automatically\n",
    "\n",
    "**Next Steps**:\n",
    "- Try different numbers of topics (`n_topics`) and see how results change\n",
    "- Experiment with preprocessing (stemming, stop words removal)\n",
    "- Use topic probabilities to handle CVs that belong to multiple topics\n",
    "- Visualize topics using tools like pyLDAvis\n",
    "\n",
    "**References**:\n",
    "- [Scikit-learn LDA documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html)\n",
    "- [Topic modeling visualization guide](https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8790015",
   "metadata": {},
   "source": [
    "\n",
    "## Module 1 Synthesis: The Complete Pipeline\n",
    "\n",
    "Congratulations! You've completed **Module 1: Text Analysis with Statistical NLP**. Let's reflect on the journey and see how all the pieces fit together.\n",
    "\n",
    "### The Circular Learning Experience\n",
    "\n",
    "Remember the question chain we started with? Let's trace how we answered each question and built a complete NLP pipeline:\n",
    "\n",
    "1. **\"What is NLP?\"** → We learned that NLP bridges computers and human language, with applications in understanding and generation.\n",
    "\n",
    "2. **\"How do we extract patterns from text?\"** → We used **Regular Expressions** to find, match, and manipulate text patterns—essential for preprocessing.\n",
    "\n",
    "3. **\"How do we understand our data?\"** → We performed **Exploratory Data Analysis (EDA)** on corpora to assess data quality, vocabulary characteristics, and preprocessing needs.\n",
    "\n",
    "4. **\"How do we prepare text for ML?\"** → We applied **Preprocessing** techniques (cleaning, normalization, tokenization, stemming) to transform raw text into clean tokens.\n",
    "\n",
    "5. **\"How do we convert text to numbers?\"** → We used **Vectorization** (BoW, TF-IDF) to convert text into numerical features that ML models can process.\n",
    "\n",
    "6. **\"How do we build classifiers?\"** → We built **Text Classification** models (like sentiment analysis) using vectorized features and supervised learning.\n",
    "\n",
    "7. **\"How do we search documents?\"** → We implemented **Information Retrieval** systems using TF-IDF and cosine similarity to find relevant documents.\n",
    "\n",
    "8. **\"How do we discover topics?\"** → We applied **Topic Modeling** (LDA) to automatically organize unlabeled documents by discovering hidden topics.\n",
    "\n",
    "### The Complete NLP Pipeline\n",
    "\n",
    "Throughout this module, you've learned to build a complete NLP pipeline:\n",
    "\n",
    "```\n",
    "Raw Text\n",
    "    ↓\n",
    "[Regex: Pattern Extraction]\n",
    "    ↓\n",
    "[Corpus & EDA: Understanding Data]\n",
    "    ↓\n",
    "[Preprocessing: Cleaning & Normalization]\n",
    "    ↓\n",
    "[Vectorization: Text → Numbers]\n",
    "    ↓\n",
    "[Modeling: Classification / IR / Topic Modeling]\n",
    "    ↓\n",
    "Actionable Insights\n",
    "```\n",
    "\n",
    "### Key Skills You've Acquired\n",
    "\n",
    "By completing this module, you can now:\n",
    "\n",
    "✅ **Build supervised ML text classification pipelines**\n",
    "- Preprocess Arabic and English text\n",
    "- Vectorize text using BoW and TF-IDF\n",
    "- Train and evaluate classifiers\n",
    "- Interpret model results\n",
    "\n",
    "✅ **Apply keyword-based information retrieval**\n",
    "- Implement TF-IDF-based search engines\n",
    "- Measure document similarity using cosine similarity\n",
    "- Rank and retrieve relevant documents\n",
    "\n",
    "✅ **Apply unsupervised ML for document organization**\n",
    "- Discover hidden topics using LDA\n",
    "- Organize unlabeled documents automatically\n",
    "- Interpret topic modeling results\n",
    "\n",
    "### The Foundation for What's Next\n",
    "\n",
    "This module focused on **statistical NLP**—traditional methods that work well for many tasks. In **Module 2**, you'll learn about **Deep Learning approaches** (embeddings, transformers) that build on these foundations to achieve even better performance.\n",
    "\n",
    "**What you learned here is still valuable:**\n",
    "- Preprocessing techniques apply to both statistical and deep learning methods\n",
    "- Understanding vectorization helps you understand embeddings\n",
    "- EDA is always the first step, regardless of the approach\n",
    "- The pipeline structure (preprocess → vectorize → model) remains the same\n",
    "\n",
    "### Reflection Questions\n",
    "\n",
    "Before moving to Module 2, consider:\n",
    "\n",
    "1. **When would you use statistical NLP vs. deep learning?**\n",
    "   - Statistical NLP: Fast, interpretable, works with small data\n",
    "   - Deep Learning: Better accuracy, requires more data and computation\n",
    "\n",
    "2. **What preprocessing steps are most important?**\n",
    "   - Depends on your data and task, but EDA always guides the decision\n",
    "\n",
    "3. **How does TF-IDF differ from BoW?**\n",
    "   - BoW: Simple word counts\n",
    "   - TF-IDF: Weighted counts that emphasize distinctive words\n",
    "\n",
    "4. **When would you use topic modeling vs. classification?**\n",
    "   - Classification: When you have labels and want to predict categories\n",
    "   - Topic Modeling: When you have no labels and want to discover structure\n",
    "\n",
    "### The Journey Continues\n",
    "\n",
    "You've built a solid foundation in statistical NLP. The concepts you've learned—preprocessing, vectorization, classification, retrieval, and topic modeling—are the building blocks for more advanced techniques.\n",
    "\n",
    "**Next Module Preview:**\n",
    "- **Module 2** introduces **Deep Learning for NLP**:\n",
    "  - Tokenization with modern tools (WordPiece, BPE)\n",
    "  - Word embeddings (Word2Vec, GloVe, contextual embeddings)\n",
    "  - Transformers and BERT\n",
    "  - Fine-tuning pre-trained models\n",
    "\n",
    "The journey from statistical NLP to deep learning is a natural progression—you'll see how embeddings generalize vectorization, how transformers improve on traditional methods, and how pre-trained models leverage the foundations you've built.\n",
    "\n",
    "---\n",
    "\n",
    "**Module 1 Complete! 🎉**\n",
    "\n",
    "You now have the skills to work with text data using statistical methods. You understand the complete pipeline from raw text to actionable insights, and you're ready to explore the power of deep learning in Module 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w5-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
